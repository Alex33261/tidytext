---
title: "Parsing Text using Dictionaries"
author: "Colin Fay and Julia Silge"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Parsing Text using Dictionaries}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## What can a dictionary-based approach offer for non-English languages?

Rules for delimiting between words vary from one language to another. For example, French uses the apostrophe as a delimiter between an article and a noun when this noun starts with a vowel. For exemple, "l'arriere" is considered two words in French: "le + arriere" contracted to "l'arriere". 

If we tokenize French with many tokenization approaches including what is implemented in [tokenizers](https://github.com/ropensci/tokenizers), the split is not made on the apostrophe. 

```{r}
library(dplyr)
library(tidytext)

df_fr <- tibble(text = c("C'est l'arriere-cuisine.", "On s'y trouve."))
unnest_tokens(df_fr, word, text)
```

Here, we end up with six tokens where we should have nine, if we want to count the contracted words separately. 

## Using tidytext with dictionary-based word identifications 

Instead of straightforward tokenization, we can transform our text into a tidy format using a dictionary-based approach. This is implemented using [`hunspell` dictionaries and the `hunspell` parser](https://github.com/ropensci/hunspell).

### With included dictionaries

You can get the list of dictionaries available in tidytext with `supported_languages()`. 

```{r}
supported_languages()
```

These `hunspell` dictionaries are available in the `extdata` folder of the tidytext package. 

To transform text to a tidy data frame using one of these dictionaries, use the `lang` argument in the `unnest_tokens()` function. 

```{r}
unnest_tokens(df_fr, word, text, lang = "french") 
```

Here, we can see the split is done with the apostrophe, giving nine tokens. 

You can perform the same kinds of tokenization as with English.

```{r}
unnest_tokens(df_fr, word, text, lang = "french", token = "ngrams", n = 2) 
```

You can also unnest other formats, such as HTML.

```{r}
data_frame(row = 1:2,
           text = c("<h1>Du text <b>d'abord</b>", "<a href='example.com'>C'est l'ancien site</a>")) %>%
  unnest_tokens(word, text, format = "html", lang = "french")
```


### With your own dictionnary

You can pass your own `hunspell` dictionary to `unnest_tokens()` by specifying 
`lang = "custom"`, and `dict = "path/to/your/dict`.

```{r}
df_ice <- tibble(text = "Eitt tungumál er aldrei nóg")
my_dict <- system.file("extdata/icelandic.aff", package = "tidytext")

unnest_tokens(df_ice, word, text, lang = "custom", dict = my_dict) 
```

