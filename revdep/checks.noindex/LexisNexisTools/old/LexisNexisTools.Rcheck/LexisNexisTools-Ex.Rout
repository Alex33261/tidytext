
R version 3.5.3 (2019-03-11) -- "Great Truth"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "LexisNexisTools"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('LexisNexisTools')
LexisNexisTools Version 0.2.2
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("lnt_add")
> ### * lnt_add
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_add
> ### Title: Adds or replaces articles
> ### Aliases: lnt_add
> 
> ### ** Examples
> 
> # Make LNToutput object from sample
> LNToutput <- lnt_read(lnt_sample())
Creating LNToutput from input 1 files...
	...files loaded [0.0039 secs]
	...articles split [0.028 secs]
	...lengths extracted [0.029 secs]
	...newspapers extracted [0.03 secs]
	...dates extracted [0.035 secs]
	...authors extracted [0.037 secs]
	...sections extracted [0.038 secs]
	...editions extracted [0.038 secs]
	...headlines extracted [0.04 secs]
	...dates converted [0.058 secs]
	...metadata extracted [0.067 secs]
	...article texts extracted [0.073 secs]
	...paragraphs extracted [0.098 secs]
	...superfluous whitespace removed from articles [0.10 secs]
	...superfluous whitespace removed from paragraphs [0.11 secs]
Elapsed time: 0.11 secs
> 
> # extract meta and make corrections
> correction <- LNToutput@meta[grepl("Wikipedia", LNToutput@meta$Headline), ]
> correction$Newspaper <- "Wikipedia"
> 
> # replace corrected meta information
> LNToutput <- lnt_add(to = LNToutput, what = correction, where = "meta", replace = TRUE)
2 entries in meta replaced, 0 newly added.
> 
> 
> 
> cleanEx()
> nameEx("lnt_asDate")
> ### * lnt_asDate
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_asDate
> ### Title: Convert Strings to dates
> ### Aliases: lnt_asDate
> 
> ### ** Examples
> 
> LNToutput <- lnt_read(lnt_sample(), convert_date = FALSE)
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
Creating LNToutput from input 1 files...
	...files loaded [0.0012 secs]
	...articles split [0.015 secs]
	...lengths extracted [0.016 secs]
	...newspapers extracted [0.017 secs]
	...dates extracted [0.02 secs]
	...authors extracted [0.021 secs]
	...sections extracted [0.022 secs]
	...editions extracted [0.023 secs]
	...headlines extracted [0.025 secs]
	...metadata extracted [0.029 secs]
	...article texts extracted [0.033 secs]
	...paragraphs extracted [0.041 secs]
	...superfluous whitespace removed from articles [0.046 secs]
	...superfluous whitespace removed from paragraphs [0.052 secs]
Elapsed time: 0.052 secs
> d <- lnt_asDate(LNToutput@meta$Date)
> d
 [1] "2010-01-11" "2010-01-11" "2010-01-11" "2010-01-11" "2010-01-11"
 [6] "2010-01-11" "2010-01-08" "2010-01-10" "2010-01-10" "2010-01-09"
> 
> 
> 
> cleanEx()
> nameEx("lnt_convert")
> ### * lnt_convert
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_convert
> ### Title: Convert LNToutput to other formats
> ### Aliases: lnt_convert lnt2rDNA lnt2quanteda lnt2tm lnt2cptools
> ###   lnt2SQLite
> 
> ### ** Examples
> 
> LNToutput <- lnt_read(lnt_sample())
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
Creating LNToutput from input 1 files...
	...files loaded [0.0016 secs]
	...articles split [0.011 secs]
	...lengths extracted [0.011 secs]
	...newspapers extracted [0.012 secs]
	...dates extracted [0.015 secs]
	...authors extracted [0.016 secs]
	...sections extracted [0.017 secs]
	...editions extracted [0.017 secs]
	...headlines extracted [0.02 secs]
	...dates converted [0.028 secs]
	...metadata extracted [0.031 secs]
	...article texts extracted [0.035 secs]
	...paragraphs extracted [0.046 secs]
	...superfluous whitespace removed from articles [0.05 secs]
	...superfluous whitespace removed from paragraphs [0.058 secs]
Elapsed time: 0.058 secs
> 
> docs <- lnt_convert(LNToutput, to = "rDNA")
> 
> corpus <- lnt_convert(LNToutput, to = "quanteda")
> 
> dbloc <- lnt_convert(LNToutput, to = "lnt2SQLite")
> 
> tCorpus <- lnt_convert(LNToutput, to = "corpustools")
> 
> tidy <- lnt_convert(LNToutput, to = "tidytext")
> 
> Corpus <- lnt_convert(LNToutput, to = "tm")
> 
> 
> 
> cleanEx()
> nameEx("lnt_diff")
> ### * lnt_diff
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_diff
> ### Title: Display diff of similar articles
> ### Aliases: lnt_diff
> 
> ### ** Examples
> 
> # Test similarity of articles
> duplicates.df <- lnt_similarity(LNToutput = lnt_read(lnt_sample()),
+                                 threshold = 0.95)
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
Creating LNToutput from input 1 files...
	...files loaded [0.0015 secs]
	...articles split [0.014 secs]
	...lengths extracted [0.015 secs]
	...newspapers extracted [0.015 secs]
	...dates extracted [0.019 secs]
	...authors extracted [0.021 secs]
	...sections extracted [0.021 secs]
	...editions extracted [0.022 secs]
	...headlines extracted [0.024 secs]
	...dates converted [0.032 secs]
	...metadata extracted [0.034 secs]
	...article texts extracted [0.038 secs]
	...paragraphs extracted [0.044 secs]
	...superfluous whitespace removed from articles [0.047 secs]
	...superfluous whitespace removed from paragraphs [0.051 secs]
Elapsed time: 0.051 secs
Checking similiarity for 10 articles over 4 dates...
	...quanteda dfm construced for similarity comparison [0.34 secs].	...processing date 2010-01-08: 0 duplicates found [0.34 secs]. 			...processing date 2010-01-09: 0 duplicates found [0.34 secs]. 			...processing date 2010-01-10: 0 duplicates found [0.42 secs]. 			...processing date 2010-01-11: 15 duplicates found [6.00 secs]. 		
Threshold = 0.95; 4 days processed; 5 duplicates found; in 6.00 secs> 
> lnt_diff(duplicates.df, min = 0.18, max = 0.30)
> 
> 
> 
> cleanEx()
> nameEx("lnt_lookup")
> ### * lnt_lookup
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_lookup
> ### Title: Lookup keywords in articles
> ### Aliases: lnt_lookup
> 
> ### ** Examples
> 
> # Make LNToutput object from sample
> LNToutput <- lnt_read(lnt_sample())
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
Creating LNToutput from input 1 files...
	...files loaded [0.0016 secs]
	...articles split [0.01 secs]
	...lengths extracted [0.011 secs]
	...newspapers extracted [0.011 secs]
	...dates extracted [0.016 secs]
	...authors extracted [0.018 secs]
	...sections extracted [0.019 secs]
	...editions extracted [0.019 secs]
	...headlines extracted [0.022 secs]
	...dates converted [0.028 secs]
	...metadata extracted [0.03 secs]
	...article texts extracted [0.036 secs]
	...paragraphs extracted [0.043 secs]
	...superfluous whitespace removed from articles [0.046 secs]
	...superfluous whitespace removed from paragraphs [0.049 secs]
Elapsed time: 0.049 secs
> 
> # Lookup keywords
> LNToutput@meta$Keyword <- lnt_lookup(LNToutput,
+                                      "statistical computing")
   |                                                  | 0 % ~calculating     |+++++                                             | 10% ~00s             |++++++++++                                        | 20% ~00s             |+++++++++++++++                                   | 30% ~00s             |++++++++++++++++++++                              | 40% ~00s             |+++++++++++++++++++++++++                         | 50% ~00s             |++++++++++++++++++++++++++++++                    | 60% ~00s             |+++++++++++++++++++++++++++++++++++               | 70% ~00s             |++++++++++++++++++++++++++++++++++++++++         | 80% ~00s             |+++++++++++++++++++++++++++++++++++++++++++++    | 90% ~00s             |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed = 00s
> 
> # Keep only articles which mention the keyword
> LNToutput_stat <- LNToutput[!sapply(LNToutput@meta$Keyword, is.null)]
> 
> # Covert list of keywords to string
> LNToutput@meta$Keyword <- sapply(LNToutput@meta$Keyword, toString)
> 
> 
> 
> cleanEx()
> nameEx("lnt_read")
> ### * lnt_read
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_read
> ### Title: Read in a LexisNexis TXT file
> ### Aliases: lnt_read
> 
> ### ** Examples
> 
> LNToutput <- lnt_read(lnt_sample())
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
Creating LNToutput from input 1 files...
	...files loaded [0.0012 secs]
	...articles split [0.012 secs]
	...lengths extracted [0.012 secs]
	...newspapers extracted [0.013 secs]
	...dates extracted [0.016 secs]
	...authors extracted [0.017 secs]
	...sections extracted [0.018 secs]
	...editions extracted [0.019 secs]
	...headlines extracted [0.021 secs]
	...dates converted [0.029 secs]
	...metadata extracted [0.032 secs]
	...article texts extracted [0.035 secs]
	...paragraphs extracted [0.05 secs]
	...superfluous whitespace removed from articles [0.054 secs]
	...superfluous whitespace removed from paragraphs [0.057 secs]
Elapsed time: 0.057 secs
> meta.df <- LNToutput@meta
> articles.df <- LNToutput@articles
> paragraphs.df <- LNToutput@paragraphs
> 
> 
> 
> cleanEx()
> nameEx("lnt_rename")
> ### * lnt_rename
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_rename
> ### Title: Assign proper names to LexisNexis TXT files
> ### Aliases: lnt_rename
> ### Keywords: LexisNexis
> 
> ### ** Examples
> 
> 
> # Copy sample file to current wd
> lnt_sample()
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
[1] "/Users/juliasilge/Work/tidytext/tidytext/revdep/checks.noindex/LexisNexisTools/old/LexisNexisTools.Rcheck/sample.TXT"
> 
> # Rename files in current wd and report back if successful
>  ## Not run: 
> ##D report.df <- lnt_rename(recursive = FALSE,
> ##D                         report = TRUE)
> ## End(Not run)
> 
> # Or provide file name(s)
> my_files<-list.files(pattern = ".txt", full.names = TRUE,
+                      recursive = TRUE, ignore.case = TRUE)
> report.df <- lnt_rename(x = my_files,
+                         recursive = FALSE,
+                         report = TRUE)
in 0.0028 secs [changes were only simulated]> 
> # Or provide folder name(s)
> report.df <- lnt_rename(x = getwd())
in 0.001 secs [changes were only simulated]> 
> report.df
                                                                                                             name_orig
1 /Users/juliasilge/Work/tidytext/tidytext/revdep/checks.noindex/LexisNexisTools/old/LexisNexisTools.Rcheck/sample.TXT
                                                                                                                                         name_new
1 /Users/juliasilge/Work/tidytext/tidytext/revdep/checks.noindex/LexisNexisTools/old/LexisNexisTools.Rcheck/SampleFile_20091201-20100511_1-10.txt
   status
1 renamed
> 
> 
> 
> cleanEx()
> nameEx("lnt_sample")
> ### * lnt_sample
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_sample
> ### Title: Provides a small sample TXT file
> ### Aliases: lnt_sample
> 
> ### ** Examples
> 
> lnt_sample()
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
[1] "/Users/juliasilge/Work/tidytext/tidytext/revdep/checks.noindex/LexisNexisTools/old/LexisNexisTools.Rcheck/sample.TXT"
> 
> 
> 
> cleanEx()
> nameEx("lnt_similarity")
> ### * lnt_similarity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_similarity
> ### Title: Check for highly similar articles.
> ### Aliases: lnt_similarity
> ### Keywords: similarity
> 
> ### ** Examples
> 
> # Copy sample file to current wd
> lnt_sample()
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
[1] "/Users/juliasilge/Work/tidytext/tidytext/revdep/checks.noindex/LexisNexisTools/old/LexisNexisTools.Rcheck/sample.TXT"
> 
> # Convert raw file to LNToutput object
> LNToutput <- lnt_read(lnt_sample())
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
Creating LNToutput from input 1 files...
	...files loaded [0.0012 secs]
	...articles split [0.0082 secs]
	...lengths extracted [0.0088 secs]
	...newspapers extracted [0.0094 secs]
	...dates extracted [0.013 secs]
	...authors extracted [0.015 secs]
	...sections extracted [0.016 secs]
	...editions extracted [0.017 secs]
	...headlines extracted [0.018 secs]
	...dates converted [0.025 secs]
	...metadata extracted [0.027 secs]
	...article texts extracted [0.03 secs]
	...paragraphs extracted [0.039 secs]
	...superfluous whitespace removed from articles [0.043 secs]
	...superfluous whitespace removed from paragraphs [0.046 secs]
Elapsed time: 0.046 secs
> 
> # Test similarity of articles
> duplicates.df <- lnt_similarity(texts = LNToutput@articles$Article,
+                                 dates = LNToutput@meta$Date,
+                                 IDs = LNToutput@articles$ID)
Checking similiarity for 10 articles over 4 dates...
	...quanteda dfm construced for similarity comparison [0.061 secs].	...processing date 2010-01-08: 0 duplicates found [0.061 secs]. 			...processing date 2010-01-09: 0 duplicates found [0.062 secs]. 			...processing date 2010-01-10: 0 duplicates found [0.11 secs]. 			...processing date 2010-01-11: 9 duplicates found [4.50 secs]. 		
Threshold = 0.99; 4 days processed; 4 duplicates found; in 4.50 secs> 
> # Remove instances with a high relative distance
> duplicates.df <- duplicates.df[duplicates.df$rel_dist < 0.2]
> 
> # Create three separate data.frames from cleaned LNToutput object
> LNToutput <- LNToutput[!LNToutput@meta$ID %in%
+                          duplicates.df$ID_duplicate]
> meta.df <- LNToutput@meta
> articles.df <- LNToutput@articles
> paragraphs.df <- LNToutput@paragraphs
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  13.515 2.005 15.901 0.004 0.006 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
