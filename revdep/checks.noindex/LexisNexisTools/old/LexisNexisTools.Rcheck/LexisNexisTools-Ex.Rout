
R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "LexisNexisTools"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('LexisNexisTools')
LexisNexisTools Version 0.2.0
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("lnt_add")
> ### * lnt_add
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_add
> ### Title: Adds or replaces articles
> ### Aliases: lnt_add
> 
> ### ** Examples
> 
> # Make LNToutput object from sample
> LNToutput <- lnt_read(lnt_sample())
Creating LNToutput from input 1 files...
	...files loaded [0.0038 secs]
	...articles split [0.013 secs]
	...lengths extracted [0.014 secs]
	...newspapers extracted [0.014 secs]
	...dates extracted [0.024 secs]
	...authors extracted [0.025 secs]
	...sections extracted [0.025 secs]
	...editions extracted [0.026 secs]
	...headlines extracted [0.027 secs]
	...dates converted [0.048 secs]
	...metadata extracted [0.051 secs]
	...article texts extracted [0.054 secs]
	...paragraphs extracted [0.066 secs]
	...superfluous whitespace removed from articles [0.068 secs]
	...superfluous whitespace removed from paragraphs [0.07 secs]
Elapsed time: 0.07 secs
> 
> # extract meta and make corrections
> correction <- LNToutput@meta[grepl("Wikipedia", LNToutput@meta$Headline), ]
> correction$Newspaper <- "Wikipedia"
> 
> # replace corrected meta information
> LNToutput <- lnt_add(to = LNToutput, what = correction, where = "meta", replace = TRUE)
2 entries in meta replaced, 0 newly added.
> 
> 
> 
> cleanEx()
> nameEx("lnt_asDate")
> ### * lnt_asDate
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_asDate
> ### Title: Convert Strings to dates
> ### Aliases: lnt_asDate
> 
> ### ** Examples
> 
> LNToutput <- lnt_read(lnt_sample(), convert_date = FALSE)
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
Creating LNToutput from input 1 files...
	...files loaded [7e-04 secs]
	...articles split [0.0085 secs]
	...lengths extracted [0.009 secs]
	...newspapers extracted [0.0092 secs]
	...dates extracted [0.011 secs]
	...authors extracted [0.012 secs]
	...sections extracted [0.012 secs]
	...editions extracted [0.012 secs]
	...headlines extracted [0.013 secs]
	...metadata extracted [0.014 secs]
	...article texts extracted [0.017 secs]
	...paragraphs extracted [0.02 secs]
	...superfluous whitespace removed from articles [0.022 secs]
	...superfluous whitespace removed from paragraphs [0.024 secs]
Elapsed time: 0.025 secs
> d <- lnt_asDate(LNToutput@meta$Date)
> d
 [1] "2010-01-11" "2010-01-11" "2010-01-11" "2010-01-11" "2010-01-11"
 [6] "2010-01-11" "2010-01-08" "2010-01-10" "2010-01-10" "2010-01-09"
> 
> 
> 
> cleanEx()
> nameEx("lnt_convert")
> ### * lnt_convert
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_convert
> ### Title: Convert LNToutput to other formats
> ### Aliases: lnt_convert lnt2rDNA lnt2quanteda lnt2tm lnt2cptools
> ###   lnt2SQLite
> 
> ### ** Examples
> 
> LNToutput <- lnt_read(lnt_sample())
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
Creating LNToutput from input 1 files...
	...files loaded [7e-04 secs]
	...articles split [0.011 secs]
	...lengths extracted [0.012 secs]
	...newspapers extracted [0.012 secs]
	...dates extracted [0.014 secs]
	...authors extracted [0.016 secs]
	...sections extracted [0.016 secs]
	...editions extracted [0.016 secs]
	...headlines extracted [0.017 secs]
	...dates converted [0.021 secs]
	...metadata extracted [0.023 secs]
	...article texts extracted [0.025 secs]
	...paragraphs extracted [0.029 secs]
	...superfluous whitespace removed from articles [0.031 secs]
	...superfluous whitespace removed from paragraphs [0.034 secs]
Elapsed time: 0.034 secs
> 
> docs <- lnt_convert(LNToutput, to = "rDNA")
> 
> corpus <- lnt_convert(LNToutput, to = "quanteda")
> 
> dbloc <- lnt_convert(LNToutput, to = "lnt2SQLite")
> 
> tCorpus <- lnt_convert(LNToutput, to = "corpustools")
> 
> tidy <- lnt_convert(LNToutput, to = "tidytext")
> 
> Corpus <- lnt_convert(LNToutput, to = "tm")
> 
> 
> 
> cleanEx()
> nameEx("lnt_diff")
> ### * lnt_diff
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_diff
> ### Title: Display diff of similar articles
> ### Aliases: lnt_diff
> 
> ### ** Examples
> 
> # Test similarity of articles
> duplicates.df <- lnt_similarity(LNToutput = lnt_read(lnt_sample()),
+                                 threshold = 0.95)
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
Creating LNToutput from input 1 files...
	...files loaded [0.0012 secs]
	...articles split [0.01 secs]
	...lengths extracted [0.011 secs]
	...newspapers extracted [0.011 secs]
	...dates extracted [0.013 secs]
	...authors extracted [0.013 secs]
	...sections extracted [0.014 secs]
	...editions extracted [0.014 secs]
	...headlines extracted [0.014 secs]
	...dates converted [0.018 secs]
	...metadata extracted [0.019 secs]
	...article texts extracted [0.021 secs]
	...paragraphs extracted [0.024 secs]
	...superfluous whitespace removed from articles [0.026 secs]
	...superfluous whitespace removed from paragraphs [0.028 secs]
Elapsed time: 0.028 secs
Checking similiarity for 10 articles over 4 dates...
	...quanteda dfm construced for similarity comparison [0.081 secs].	...processing date 2010-01-08: 0 duplicates found [0.081 secs]. 			...processing date 2010-01-09: 0 duplicates found [0.081 secs]. 			...processing date 2010-01-10: 0 duplicates found [0.23 secs]. 			...processing date 2010-01-11: 15 duplicates found [4.46 secs]. 		
Threshold = 0.95; 4 days processed; 5 duplicates found; in 4.46 secs> 
> lnt_diff(duplicates.df, min = 0.18, max = 0.30)
> 
> 
> 
> cleanEx()
> nameEx("lnt_lookup")
> ### * lnt_lookup
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_lookup
> ### Title: Lookup keywords in articles
> ### Aliases: lnt_lookup
> 
> ### ** Examples
> 
> # Make LNToutput object from sample
> LNToutput <- lnt_read(lnt_sample())
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
Creating LNToutput from input 1 files...
	...files loaded [0.006 secs]
	...articles split [0.015 secs]
	...lengths extracted [0.016 secs]
	...newspapers extracted [0.016 secs]
	...dates extracted [0.019 secs]
	...authors extracted [0.02 secs]
	...sections extracted [0.02 secs]
	...editions extracted [0.021 secs]
	...headlines extracted [0.021 secs]
	...dates converted [0.025 secs]
	...metadata extracted [0.027 secs]
	...article texts extracted [0.029 secs]
	...paragraphs extracted [0.034 secs]
	...superfluous whitespace removed from articles [0.037 secs]
	...superfluous whitespace removed from paragraphs [0.039 secs]
Elapsed time: 0.039 secs
> 
> # Lookup keywords
> LNToutput@meta$Keyword <- lnt_lookup(LNToutput,
+                                      "statistical computing")
   |                                                  | 0 % ~calculating     |+++++                                             | 10% ~00s             |++++++++++                                        | 20% ~00s             |+++++++++++++++                                   | 30% ~00s             |++++++++++++++++++++                              | 40% ~00s             |+++++++++++++++++++++++++                         | 50% ~00s             |++++++++++++++++++++++++++++++                    | 60% ~00s             |+++++++++++++++++++++++++++++++++++               | 70% ~00s             |++++++++++++++++++++++++++++++++++++++++         | 80% ~00s             |+++++++++++++++++++++++++++++++++++++++++++++    | 90% ~00s             |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed = 00s
> 
> # Keep only articles which mention the keyword
> LNToutput_stat <- LNToutput[!sapply(LNToutput@meta$Keyword, is.null)]
> 
> # Covert list of keywords to string
> LNToutput@meta$Keyword <- sapply(LNToutput@meta$Keyword, toString)
> 
> 
> 
> cleanEx()
> nameEx("lnt_read")
> ### * lnt_read
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_read
> ### Title: Read in a LexisNexis TXT file
> ### Aliases: lnt_read
> 
> ### ** Examples
> 
> LNToutput <- lnt_read(lnt_sample())
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
Creating LNToutput from input 1 files...
	...files loaded [0.00088 secs]
	...articles split [0.0078 secs]
	...lengths extracted [0.0083 secs]
	...newspapers extracted [0.0087 secs]
	...dates extracted [0.01 secs]
	...authors extracted [0.011 secs]
	...sections extracted [0.012 secs]
	...editions extracted [0.012 secs]
	...headlines extracted [0.012 secs]
	...dates converted [0.016 secs]
	...metadata extracted [0.018 secs]
	...article texts extracted [0.02 secs]
	...paragraphs extracted [0.03 secs]
	...superfluous whitespace removed from articles [0.032 secs]
	...superfluous whitespace removed from paragraphs [0.035 secs]
Elapsed time: 0.035 secs
> meta.df <- LNToutput@meta
> articles.df <- LNToutput@articles
> paragraphs.df <- LNToutput@paragraphs
> 
> 
> 
> cleanEx()
> nameEx("lnt_rename")
> ### * lnt_rename
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_rename
> ### Title: Assign proper names to LexisNexis TXT files
> ### Aliases: lnt_rename
> ### Keywords: LexisNexis
> 
> ### ** Examples
> 
> 
> # Copy sample file to current wd
> lnt_sample()
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
[1] "/Volumes/Data1TB/Google Drive/data_science/runconf16/tidytext/revdep/checks.noindex/LexisNexisTools/old/LexisNexisTools.Rcheck/sample.TXT"
> 
> # Rename files in current wd and report back if successful
>  ## Not run: 
> ##D report.df <- lnt_rename(recursive = FALSE,
> ##D                         report = TRUE)
> ## End(Not run)
> 
> # Or provide file name(s)
> my_files<-list.files(pattern = ".txt", full.names = TRUE,
+                      recursive = TRUE, ignore.case = TRUE)
> report.df <- lnt_rename(x = my_files,
+                         recursive = FALSE,
+                         report = TRUE)
in 0.002 secs [changes were only simulated]> 
> # Or provide folder name(s)
> report.df <- lnt_rename(x = getwd())
in 0.00069 secs [changes were only simulated]> 
> report.df
                                                                                                                                  name_orig
1 /Volumes/Data1TB/Google Drive/data_science/runconf16/tidytext/revdep/checks.noindex/LexisNexisTools/old/LexisNexisTools.Rcheck/sample.TXT
                                                                                                                                                              name_new
1 /Volumes/Data1TB/Google Drive/data_science/runconf16/tidytext/revdep/checks.noindex/LexisNexisTools/old/LexisNexisTools.Rcheck/SampleFile_20091201-20100511_1-10.txt
   status
1 renamed
> 
> 
> 
> cleanEx()
> nameEx("lnt_sample")
> ### * lnt_sample
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_sample
> ### Title: Provides a small sample TXT file
> ### Aliases: lnt_sample
> 
> ### ** Examples
> 
> lnt_sample()
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
[1] "/Volumes/Data1TB/Google Drive/data_science/runconf16/tidytext/revdep/checks.noindex/LexisNexisTools/old/LexisNexisTools.Rcheck/sample.TXT"
> 
> 
> 
> cleanEx()
> nameEx("lnt_similarity")
> ### * lnt_similarity
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: lnt_similarity
> ### Title: Check for highly similar articles.
> ### Aliases: lnt_similarity
> ### Keywords: similarity
> 
> ### ** Examples
> 
> # Copy sample file to current wd
> lnt_sample()
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
[1] "/Volumes/Data1TB/Google Drive/data_science/runconf16/tidytext/revdep/checks.noindex/LexisNexisTools/old/LexisNexisTools.Rcheck/sample.TXT"
> 
> # Convert raw file to LNToutput object
> LNToutput <- lnt_read(lnt_sample())
Warning in lnt_sample() :
  Sample file exists in wd. Use overwrite = TRUE to create fresh sample file.
Creating LNToutput from input 1 files...
	...files loaded [0.00096 secs]
	...articles split [0.0077 secs]
	...lengths extracted [0.0081 secs]
	...newspapers extracted [0.0084 secs]
	...dates extracted [0.0098 secs]
	...authors extracted [0.01 secs]
	...sections extracted [0.011 secs]
	...editions extracted [0.011 secs]
	...headlines extracted [0.011 secs]
	...dates converted [0.014 secs]
	...metadata extracted [0.016 secs]
	...article texts extracted [0.018 secs]
	...paragraphs extracted [0.021 secs]
	...superfluous whitespace removed from articles [0.023 secs]
	...superfluous whitespace removed from paragraphs [0.026 secs]
Elapsed time: 0.026 secs
> 
> # Test similarity of articles
> duplicates.df <- lnt_similarity(texts = LNToutput@articles$Article,
+                                 dates = LNToutput@meta$Date,
+                                 IDs = LNToutput@articles$ID)
Checking similiarity for 10 articles over 4 dates...
	...quanteda dfm construced for similarity comparison [0.032 secs].	...processing date 2010-01-08: 0 duplicates found [0.033 secs]. 			...processing date 2010-01-09: 0 duplicates found [0.033 secs]. 			...processing date 2010-01-10: 0 duplicates found [0.04 secs]. 			...processing date 2010-01-11: 9 duplicates found [3.06 secs]. 		
Threshold = 0.99; 4 days processed; 4 duplicates found; in 3.06 secs> 
> # Remove instances with a high relative distance
> duplicates.df <- duplicates.df[duplicates.df$rel_dist < 0.2]
> 
> # Create three separate data.frames from cleaned LNToutput object
> LNToutput <- LNToutput[!LNToutput@meta$ID %in%
+                          duplicates.df$ID_duplicate]
> meta.df <- LNToutput@meta
> articles.df <- LNToutput@articles
> paragraphs.df <- LNToutput@paragraphs
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  9.033 2.019 10.566 0.018 0.019 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
