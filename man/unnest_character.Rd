% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/unnest_char.R
\name{unnest_characters}
\alias{unnest_characters}
\alias{unnest_character_shingles}
\title{Wrapper around unnest_tokens & characters / character_shingles}
\usage{
unnest_characters(tbl, output, input, strip_non_alphanum = TRUE,
  simplify = FALSE, format = c("text", "man", "latex", "html", "xml"),
  to_lower = TRUE, drop = TRUE, collapse = NULL, ...)

unnest_character_shingles(tbl, output, input, n = 3L, n_min = n,
  strip_non_alphanum = TRUE, simplify = FALSE, format = c("text",
  "man", "latex", "html", "xml"), to_lower = TRUE, drop = TRUE,
  collapse = NULL, ...)
}
\arguments{
\item{tbl}{A data frame}

\item{output}{Output column to be created as string or symbol.}

\item{input}{Input column that gets split as string or symbol.

The output/input arguments are passed by expression and support
\link[rlang]{quasiquotation}; you can unquote strings and symbols.}

\item{strip_non_alphanum}{Should punctuation and white space be stripped?}

\item{simplify}{\code{FALSE} by default so that a consistent value is
returned regardless of length of input. If \code{TRUE}, then an input with
a single element will return a character vector of tokens instead of a
list.}

\item{format}{Either "text", "man", "latex", "html", or "xml". If not text,
this uses the hunspell tokenizer, and can tokenize only by "word"}

\item{to_lower}{Whether to convert tokens to lowercase. If tokens include
URLS (such as with \code{token = "tweets"}), such converted URLs may no
longer be correct.}

\item{drop}{Whether original input column should get dropped. Ignored
if the original input and new output column have the same name.}

\item{collapse}{Whether to combine text with newlines first in case tokens
(such as sentences or paragraphs) span multiple lines. If NULL, collapses
when token method is "ngrams", "skip_ngrams", "sentences", "lines",
"paragraphs", or "regex".}

\item{...}{Extra arguments passed on to \link[tokenizers]{tokenizers}, such
as \code{strip_punct} for "words" and "tweets", \code{n} and \code{k} for
"ngrams" and "skip_ngrams", \code{strip_url} for "tweets", and
\code{pattern} for "regex".}

\item{n}{The number of characters in each shingle. This must be an integer
greater than or equal to 1.}

\item{n_min}{This must be an integer greater than or equal to 1, and less
than or equal to \code{n}.}
}
\description{
Thes functions are a wrapper around \code{unnest_tokens( token = "characters" )}
and \code{unnest_tokens( token = "character_shingles" )}.
}
\examples{
library(dplyr)
library(janeaustenr)

d <- tibble(txt = prideprejudice)
d
d \%>\%
  unnest_characters(word, txt)
}
\seealso{
\itemize{
\item \code{\link[=unnest_tokens]{unnest_tokens()}}
}
}
