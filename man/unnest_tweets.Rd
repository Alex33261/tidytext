% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/unnest_tweets.R
\name{unnest_tweets}
\alias{unnest_tweets}
\title{Wrapper around unnest_tokens for tweets}
\usage{
unnest_tweets(tbl, output, input, stopwords = NULL, strip_punct = TRUE,
  strip_url = FALSE, simplify = FALSE, format = c("text", "man",
  "latex", "html", "xml"), to_lower = TRUE, drop = TRUE,
  collapse = NULL, ...)
}
\arguments{
\item{tbl}{A data frame}

\item{output}{Output column to be created as string or symbol.}

\item{input}{Input column that gets split as string or symbol.

The output/input arguments are passed by expression and support
\link[rlang]{quasiquotation}; you can unquote strings and symbols.}

\item{stopwords}{A character vector of stop words to be excluded.}

\item{strip_punct}{Should punctuation be stripped?}

\item{strip_url}{Should URLs (starting with \code{http(s)}) be preserved intact, or
removed entirely?}

\item{simplify}{\code{FALSE} by default so that a consistent value is
returned regardless of length of input. If \code{TRUE}, then an input with
a single element will return a character vector of tokens instead of a
list.}

\item{format}{Either "text", "man", "latex", "html", or "xml". If not text,
this uses the hunspell tokenizer, and can tokenize only by "word"}

\item{to_lower}{Whether to convert tokens to lowercase. If tokens include
URLS (such as with \code{token = "tweets"}), such converted URLs may no
longer be correct.}

\item{drop}{Whether original input column should get dropped. Ignored
if the original input and new output column have the same name.}

\item{collapse}{Whether to combine text with newlines first in case tokens
(such as sentences or paragraphs) span multiple lines. If NULL, collapses
when token method is "ngrams", "skip_ngrams", "sentences", "lines",
"paragraphs", or "regex".}

\item{...}{Extra arguments passed on to \link[tokenizers]{tokenizers}}
}
\description{
This function is a wrapper around \code{unnest_tokens( token = "tweets" )}.
}
\examples{
library(dplyr)
tweets <- tibble(
   id = 1,
   txt = "@rOpenSci and #rstats see: https://cran.r-project.org"
)

tweets \%>\%
   unnest_tokens(out, txt, token = "tweets")

}
\seealso{
\itemize{
\item \code{\link[=unnest_tokens]{unnest_tokens()}}
}
}
